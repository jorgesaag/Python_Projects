#You haven’t experienced it yet, but if you get complicated data back from a REST API, it may take you many tries to
#compose and debug code that processes that data in the way that you want. (See the Nested Data chapter.)
#It is a good practice, for many reasons, not to keep contacting a REST API to re-request the same data every
#time you run your program.

#To avoid re-requesting the same data, we will use a programming pattern known as caching. It works like this:

# 1) Before doing some expensive operation (like calling requests.get to get data from a REST API), check
#whether you have already saved (“cached”) the results that would be generated by making that request.

# 2) If so, return that same data.

# 3) If not, perform the expensive operation and save (“cache”) the results (e.g. the complicated data) in your
#cache so you won’t have to perform it again the next time.

#If you go on to learn about web development, you’ll find that you encounter caching all the time – if you’ve ever
#had the experience of seeing old data when you go to a website and thinking, “Huh, that’s weird,
#it should really be different now… why am I still seeing that?” that happens because the browser has accessed a
#cached version of the site.

#There are at least four reasons why caching is a good idea during your software development using REST APIs:

#It reduces load on the website that is providing you data. It is always nice to be courteous when using other people’s
#resources. Moreover, some websites impose rate limits: for example, after 15 requests in a 15 minute period, the site
#may start sending error responses. That will be confusing and annoying for you.

#It will make your program run faster. Connections over the Internet can take a few seconds, or even tens of seconds,
#if you are requesting a lot of data. It might not seem like much, but debugging is a lot easier when you can make a
#change in your program, run it, and get an almost instant response.

#It is harder to debug the code that processes complicated data if the content that is coming back can change on each
#run of your code. It’s amazing to be able to write programs that fetch real-time data like the available iTunes
#podcasts or the latest tweets from Twitter. But it can be hard to debug that code if you are having problems that only
#occur on certain Tweets (e.g. those in foreign languages). When you encounter problematic data, it’s helpful if you
#save a copy and can debug your program working on that saved, static copy of the data.

#It is easier to run automated tests on code that retrieves data if the data can never change, for the same reasons it
#is helpful for debugging. In fact, we rely on use of cached data in the automated tests that check your code in exercises.

#There are some downsides to caching data – for example, if you always want to find out when data has changed, and your
#default is to rely on already-cached data, then you have a problem. However, when you’re working on developing
#code that will work, caching is worth the tradeoff.

#The requests_with_caching module:

#In this book, we are providing a special module, called request_with_caching. Here’s how you’ll use this module.

#Your code will include a statement to import the module, import requests_with_caching.

#Instead of invoking requests.get(), you’ll invoke requests_with_caching.get().

#You’ll get exactly the same Response object back that you would have gotten. But you’ll also get a printout in the
#output window with one of the following three diagnostic messages:

# I) found in permanent cache
# II) found in page-specific cache
# III) new; adding to cache

#The permanent cache is contained in a file that is built into the textbook. Your program can use its contents but
#can’t add to it.

#The page-specific cache is a new file that is created the first time you make a request for a url that wasn’t in the
#permanent cache. Each subsequent request for a new url results in more data being written to the page-specific cache.
#After you run an activecode that adds something to the page-specific cache, you’ll see a little window below it where
#you can inspect the contents of the page-specific cache. When you reload the webpage, that page-specific cache will
#be gone; hence the name.

#There are a couple of other optional parameters for the function requests_with_caching.get().

#cache_file– it’s value should be a string specifying the name of the file containing the permanent cache.
#If you don’t specify anything, the default value is “permanent_cache.txt”. For the datamuse API, we’ve provide a cache
#in a file called datamuse_cache.txt. It just contains the saved response to the query for
#“https://api.datamuse.com/words?rel_rhy=funny”.

#private_keys_to_ignore– its value should be a list of strings. These are keys from the parameters dictionary that
#should be ignored when deciding whether the current request matches a previous request.
#The main purpose of this is that it allows us to return a result from the cache for some REST APIs that would
#otherwise require you to provide an API key in order to make a request. By default, it is set to [“api_key”],
#which is a query parameter used with the flickr API. You should not need to set this optional parameter.

import requests_with_caching
# it's not found in the permanent cache
res = requests_with_caching.get("https://api.datamuse.com/words?rel_rhy=happy", permanent_cache_file="datamuse_cache.txt")
print(res.text[:100])
# this time it will be found in the temporary cache
res = requests_with_caching.get("https://api.datamuse.com/words?rel_rhy=happy", permanent_cache_file="datamuse_cache.txt")
# This one is in the permanent cache.
res = requests_with_caching.get("https://api.datamuse.com/words?rel_rhy=funny", permanent_cache_file="datamuse_cache.txt")

#Implementation of the requests_with_caching module:

#You may find it useful to understand how this module works. The source code is not very complicated; we’ve reproduced
#it below. You can use it as a template for implementing code for your own caching pattern in other settings.

#This module is not available outside this textbook; in a full python environment you won’t be able to install a requests_
#with_caching module. But you can copy the code and make it work outside the textbook environment.

#We have optimized this code for conceptual simplicity, so that it is useful as a teaching tool.
#It is not very efficient, because it always stores cached contents in a file, rather than saving it in memory.
#If you are ever implementing the caching pattern just for the duration of a program’s run, you might want to save
#cached content in a python dictionary in memory rather than writing it to a file.

#The basic idea in the code is to maintain the cache as a dictionary with keys representing API requests that have been
#made, and values representing the text that was retrieved. In order to make our cache live beyond one program
#execution, we store it in a file. Hence, there are helper functions _write_to_file and read_to_file that write a cache
#dictionary to and read it from a file.

#In order for the textbook to provide a cache file that can’t be overwritten, we distinguish between the permanent file,
#which is provided as part of the online textbook, and a temporary cache file that will live only until the page is
#reloaded.